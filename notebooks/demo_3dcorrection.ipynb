{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e7e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install climetlab\n",
    "#!pip install climetlab-maelstrom-radiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36fcadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climetlab as cml\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cbaf2d",
   "metadata": {},
   "source": [
    "# Radiation emulation: 3d correction.\n",
    "\n",
    "This notebook is a sequel to demo_radiation. Please read through demo_radiation before continuing.\n",
    "\n",
    "### The task\n",
    "Existing models of radiation used in operational forecasting typically do not take into account of the 3D cloud aspect within a grid column. The ecRAD SPARTACUS (Hogan & Shonk 2012) solver takes such features into account. However this scheme is considerably more expensive than schemes such as McICA or Tripleclouds. In this task we seek to learn the difference between ecRAD predictions using the Tripleclouds solver and those using the SPARTACUS solver. \n",
    "A successful emulator of this dataset could be used as a corrective term to the Tripleclouds formulation, thereby incorporating the 3D cloud effects. By only seeking to learn the correction term, rather than the full output of the SPARTACUS solver we seek to only learn the most expensive calculations within radiative heating.\n",
    "\n",
    "Using the argument `dataset = 3dcorrection` we can get the difference between the outputs of SPARTACUS and Tripleclouds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e602065",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "As with the previous notebook data can be loaded by either specifying a **subset**, e.g. 'tier-1' or by specifying the trio of **date, timestep, patch**. \n",
    "\n",
    "In addition to those, we need to prescribe the **dataset** to be **3dcorrection**.\n",
    "\n",
    "### Subset\n",
    "Currently only 'tier-1' is supported for the 3dcorrection problem. \n",
    "### Date/timestep/patch\n",
    "These describe the start **date** of the numerical forecast used to generate the data, the **timestep** index of said forecast (note the time increment is 12 minutes, meaning step 125 corresponds to 25 hours after initialisation) and **patch** a spatial subset of globe (here the globe is divided into 16 equal regions).\n",
    "Valid values for each of the above can be found with **cmlds.valid_date** etc.\n",
    "Most start dates are from 2020, which we recommend as the training set, four start dates in 2019 are provided as validation/testing data.\n",
    "\n",
    "Currently only the first date from 2020 is uploaded. More data to come ...\n",
    "\n",
    "### If no descriptions are passed then tier-1 subset is loaded, corresponding to 2020-01-01/0/range(0,16,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2d2af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset: tier-1\n",
      "Loading date: 20200101, timestep: 0, patch: [0, 2, 4, 6, 8, 10, 12, 14]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmlds = cml.load_dataset(\n",
    "        'maelstrom-radiation',\n",
    "        dataset='3dcorrection',\n",
    "        subset='tier-1',\n",
    "        raw_inputs=False,\n",
    "    )\n",
    "\n",
    "ds = cmlds.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01ccd39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:       (column: 135680, sca_variable: 17, level: 137, col_variable: 27, half_level: 138, hl_variable: 2, p_variable: 1, level_interface: 136, inter_variable: 1)\n",
      "Dimensions without coordinates: column, sca_variable, level, col_variable, half_level, hl_variable, p_variable, level_interface, inter_variable\n",
      "Data variables:\n",
      "    sca_inputs    (column, sca_variable) float32 dask.array<chunksize=(16960, 1), meta=np.ndarray>\n",
      "    col_inputs    (column, level, col_variable) float32 dask.array<chunksize=(16960, 137, 1), meta=np.ndarray>\n",
      "    hl_inputs     (column, half_level, hl_variable) float32 dask.array<chunksize=(16960, 138, 1), meta=np.ndarray>\n",
      "    pressure_hl   (column, half_level, p_variable) float32 dask.array<chunksize=(16960, 138, 1), meta=np.ndarray>\n",
      "    inter_inputs  (column, level_interface, inter_variable) float32 dask.array<chunksize=(16960, 136, 1), meta=np.ndarray>\n",
      "    flux_dn_sw    (column, half_level) float32 dask.array<chunksize=(16960, 138), meta=np.ndarray>\n",
      "    flux_up_sw    (column, half_level) float32 dask.array<chunksize=(16960, 138), meta=np.ndarray>\n",
      "    flux_dn_lw    (column, half_level) float32 dask.array<chunksize=(16960, 138), meta=np.ndarray>\n",
      "    flux_up_lw    (column, half_level) float32 dask.array<chunksize=(16960, 138), meta=np.ndarray>\n",
      "    hr_sw         (column, level) float32 dask.array<chunksize=(16960, 137), meta=np.ndarray>\n",
      "    hr_lw         (column, level) float32 dask.array<chunksize=(16960, 137), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f34a3",
   "metadata": {},
   "source": [
    "The inputs and outputs for the 3dcorrection problem are the same as those for the McICA or Tripleclouds problem. Please see the previous notebook for a discussion of the inputs and outputs.\n",
    "\n",
    "Things to note. I recommend using\n",
    "**raw_inputs = false** to concatenate similar shaped variables together.\n",
    "\n",
    "### Predictors\n",
    "The direct outputs from any of the radiation schemes are the upwards and downwards fluxes for both shortwave and longwave heating. These are described on 138 \"half-levels\", which are the boundaries to the 137 model levels.\n",
    "The rest of the IFS model uses heating rates and fluxes at the boundaries (top and bottom) increment the temperatures. The heating rate is the vertical (pressure) derivative of the net (down - up) flux and is described on the 137 model levels.\n",
    "This means that there are several modelling approaches, to be used separately on the shortwave and longwave.\n",
    "\n",
    "- Predict only the fluxes. Assume that the derived heating will be accurate by producing accurate fluxes. This has been previously tried, but there were unrealistic gradients in the heating rate which degraded coupled predictions.\n",
    "- Predict the fluxes, use the custom layer below to deduce the heating rates, and use a loss which combines the mse of the fluxes and the mse of the heating rates. NB the magnitude of the heating rates is much smaller than those of the fluxes, so the inbalance of the two terms will need to be large or the heating rates will need to be rescaled.\n",
    "- Directly predict the heating rates and 4 boundary fluxes (down and up at top and bottom). NB downwards flux at the top of the atmosphere is equal to the solar_irradiance\\*cos_solar_zenith_angle for shortwave and 0 for longwave. This approach can induce energy imbalances, which can be solved with an alternate formulation, which we ignore for simplicity here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "470028a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class HRLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Layer to calculate heating rates given fluxes\n",
    "    and half-level pressures.\n",
    "    This could be used to deduce the heating rates\n",
    "    within the model so that the outputs can be \n",
    "    constrained by both fluxes and heating rates\n",
    "    \"\"\"\n",
    "    def __init__(self,name=None,**kwargs):\n",
    "        super(HRLayer, self).__init__(name=name,**kwargs)\n",
    "        self.g_cp = tf.constant(9.80665 / 1004)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def call(self, inputs):\n",
    "        fluxes_down = inputs[0] # shape batch,138,1\n",
    "        fluxes_down = inputs[1] # shape batch,138,1\n",
    "        hlpress = inputs[2] # shape batch,138,1\n",
    "        netflux = fluxes_down[...,0] - fluxes_up[...,0]\n",
    "        flux_diff = netflux[...,1:] - netflux[...,:-1]\n",
    "        net_press = hlpress[...,1:,0] - hlpress[...,:-1,0]\n",
    "        return -self.g_cp * tf.math.divide(flux_diff,net_press)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b4d89",
   "metadata": {},
   "source": [
    "# Machine learning this dataset\n",
    "A TFRecord format of this dataset has not yet been generate (work in progress). Work is also ongoing to create a `to_tfdataset` function for this dataset.\n",
    "\n",
    "# Questions?\n",
    "Please reach out if you have questions/problems on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315868c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
